{
    "version": "https://jsonfeed.org/version/1",
    "title": "玖忆 • All posts by \"接口幂等性\" tag",
    "description": "我本微末凡尘、可也心向天空",
    "home_page_url": "https://wait-you.github.io",
    "items": [
        {
            "id": "https://wait-you.github.io/2023/06/06/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E6%80%A7/",
            "url": "https://wait-you.github.io/2023/06/06/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E6%80%A7/",
            "title": "接口幂等性",
            "date_published": "2023-06-06T01:09:49.000Z",
            "content_html": "<h1 id=\"接口幂等性\"><a class=\"markdownIt-Anchor\" href=\"#接口幂等性\">#</a> 接口幂等性</h1>\n<h2 id=\"什么是幂等性\"><a class=\"markdownIt-Anchor\" href=\"#什么是幂等性\">#</a> 什么是幂等性</h2>\n<p><strong>接口幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的</strong>，不会因为多次点击而产生副作用；比如说支付场景，用户购买了商品支付成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行二次扣款，返回结果成功，用户查询语法发现多扣钱了，流水记录也变成了两条，这就是没有保证接口幂等性</p>\n<h2 id=\"哪些情况需要防止\"><a class=\"markdownIt-Anchor\" href=\"#哪些情况需要防止\">#</a> 哪些情况需要防止</h2>\n<p>用户多次点击按钮</p>\n<p>用户页面回退再次提交</p>\n<p>微服务互相调用，由于网络问题，导致请求失败，feign 触发重试机制</p>\n<p>其他业务情况</p>\n<h2 id=\"幂等解决方案将\"><a class=\"markdownIt-Anchor\" href=\"#幂等解决方案将\">#</a> 幂等解决方案将</h2>\n<h3 id=\"token机制\"><a class=\"markdownIt-Anchor\" href=\"#token机制\">#</a> token 机制</h3>\n<ol>\n<li>服务端提供了发送 token 的接口，我们在分析业务的时候，哪些业务是存在幂等问题的，就必须在执行业务前，先去获取 token，服务器会把 token 保存都 redis 中</li>\n<li>然后调用业务接口请求时，把 token 携带过去，一般放在请求头部</li>\n<li>服务器判断 token 是否存在 redis 中，存在表示第一次请求，然后删除 token，继续执行业务</li>\n<li>如果 token 不存在 redis 中，就表示是重复操作，直接返回重复标记给 client，这样就保证了业务代码，不被重复执行</li>\n</ol>\n<p>危险性：</p>\n<ol>\n<li>\n<p>先删除 token 还是后删除 token</p>\n<ol>\n<li>先删除可能导致业务确实没有执行，重试还带上之前的 token，由于放重涉及导致请求还是不能执行</li>\n<li>后删除可能导致业务处理成功，但是服务闪退，出现超时，没有删除 token，别人继续重试，导致业务被执行两遍</li>\n<li>我们最好设计为先删除 token，如果业务调用失败，就重新获取 token 再次请求</li>\n</ol>\n</li>\n<li>\n<p>Token 获取、比较和删除必须是原子操作</p>\n<ol>\n<li>\n<p>redis.get (token)、token.equals、redis.del (token)，如果这三个操作不是原子，可能导致高并发下，都 get 到同样的数据，判断都成功，继续业务执行</p>\n</li>\n<li>\n<p>可以在 redis 使用 lua 脚本完成这个操作</p>\n<div class=\"highlight-container\" data-rel=\"Lua\"><figure class=\"iseeu highlight lua\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> redis.call(<span class=\"string\">&#x27;get&#x27;</span>, KEYS[<span class=\"number\">1</span>]==ARGV[<span class=\"number\">1</span>])<span class=\"keyword\">then</span> <span class=\"keyword\">return</span> redis.call(<span class=\"string\">&#x27;del&#x27;</span>, KEYS[<span class=\"number\">1</span>])<span class=\"keyword\">else</span> <span class=\"keyword\">return</span> <span class=\"number\">0</span> <span class=\"keyword\">end</span></span><br></pre></td></tr></table></figure></div>\n</li>\n</ol>\n</li>\n</ol>\n<h3 id=\"各种锁机制\"><a class=\"markdownIt-Anchor\" href=\"#各种锁机制\">#</a> 各种锁机制</h3>\n<h4 id=\"数据库悲观锁\"><a class=\"markdownIt-Anchor\" href=\"#数据库悲观锁\">#</a> 数据库悲观锁</h4>\n<p>悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，需要根据实际情况选用，另外要注意的是，id 字段一定是主键或者唯一索引，不然很可能造成锁表的结果，处理起来会非常麻烦</p>\n<h4 id=\"数据库乐观锁\"><a class=\"markdownIt-Anchor\" href=\"#数据库乐观锁\">#</a> 数据库乐观锁</h4>\n<p>这种方法适合在更新的场景中</p>\n<p>根据 version 版本，也就是在操作数据库前先获取当前商品的 version 版本号，然后操作的时候带上此 version 号</p>\n<p>乐观锁主要使用于处理读多写少的问题</p>\n<h4 id=\"业务层分布式锁\"><a class=\"markdownIt-Anchor\" href=\"#业务层分布式锁\">#</a> 业务层分布式锁</h4>\n<p>如果多个机器可能在同一时间同时处理相同的数据，比如多台机器定时任务都拿到了相同数据处理，我们就可以加分布式锁，锁定此数据，处理完成后释放锁，获取到锁的必须先判断这个数据是否被处理过</p>\n<h3 id=\"各种唯一约束\"><a class=\"markdownIt-Anchor\" href=\"#各种唯一约束\">#</a> 各种唯一约束</h3>\n<h4 id=\"数据库唯一约束\"><a class=\"markdownIt-Anchor\" href=\"#数据库唯一约束\">#</a> 数据库唯一约束</h4>\n<p>插入数据，应该按照唯一索引进行插入，比如订单号，相同的订单号就不可能有两条记录插入</p>\n<p>这个机制是利用了数据库的主键唯一约束的特性，解决了在 insert 场景时幂等性问题，但主键的要求不能是自增的主键，这样就需要业务生成全局唯一 的主键</p>\n<p>如果是分库分表的场景下，路由规则要保证相同请求下，落地在同一个数据库和同一个表中，要不然数据库主键约束就不其效果了，因为是不同的数据库和表主键不相关</p>\n<h4 id=\"redis-set防重\"><a class=\"markdownIt-Anchor\" href=\"#redis-set防重\">#</a> redis set 防重</h4>\n<p>很多数据需要处理，只能被处理一次，比如我们可以计算数据的 MD5 将其放入 redis 的 set，每次处理数据，先看这个 MD5 是否已经存在，存在就不处理</p>\n<h3 id=\"防重表\"><a class=\"markdownIt-Anchor\" href=\"#防重表\">#</a> 防重表</h3>\n<p>使用订单号 orderNo 作为去重表的唯一索引，把唯一索引插入去重表，在进行业务操作，且他们在同一个事物中，这个保证了重复请求时，因为去重表有唯一约束，导致请求失败，避免了幂等性问题，这里要注意的是，去重表和业务表应该放在同一个库中，这样就保证了在同一个事务中，即使业务操作失败了，也会把去重表的数据回滚 ，这个很好的保证了数据的一致性</p>\n<h3 id=\"全局请求唯一id\"><a class=\"markdownIt-Anchor\" href=\"#全局请求唯一id\">#</a> 全局请求唯一 id</h3>\n<p>调用接口时，生成一个唯一的 id，redis 将数据保存到集合中（去重），存在即处理过</p>\n<p>可与使用 nginx 设置每一个请求的唯一 id</p>\n<p>proxy_set_header X-Rquest-Id $request_id;</p>\n",
            "tags": [
                "接口幂等性"
            ]
        }
    ]
}